{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = spark.read.csv(\"alldata.csv\", header = True, inferSchema = True)\n",
    "companies = spark.read.csv(\"companies.csv\", header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for repeating columns of all_Data in companies and rename by adding all_data\n",
    "for all_data_col in all_data.columns:\n",
    "    if all_data_col in companies.columns:\n",
    "        all_data = all_data.withColumnRenamed(all_data_col, all_data_col + '_all_data')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the two datasets\n",
    "joined_df = companies.join(all_data, companies[\"company name\"] == all_data[\"company\"], \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = all_data.select('location').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split location to get city\n",
    "city = location.select(F.split('location', ' ')[0].alias('city'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    city|\n",
      "+--------+\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "|Atlanta,|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city = city[city.city.contains(',')]\n",
    "city.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a temview\n",
    "city.createOrReplaceTempView('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_freq = spark.sql(\"SELECT city, COUNT(city) AS frequency FROM city GROUP BY city ORDER BY frequency \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.createOrReplaceTempView('joined_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_freq = spark.sql(\"SELECT industry, COUNT(industry) AS frequency FROM joined_df GROUP BY industry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to generate n-grams (unigram & bigram) from a given text/description.\n",
    "def generateNgrams(ngram_text, column_name):\n",
    "    tokenizer = Tokenizer(inputCol = column_name, outputCol = 'unigram')\n",
    "    ngram = NGram(n = 2, inputCol = 'unigram', outputCol = 'ngram')\n",
    "    unigram = tokenizer.transform(ngram_text)\n",
    "    bigram = ngram.transform(unigram)\n",
    "    return bigram.select(column_name, 'frequency', 'ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNgramDF():\n",
    "    city_freq_ngram = generateNgrams(city_freq, 'city')\n",
    "    companies_ngram = generateNgrams(industry_freq, 'industry')\n",
    "    return city_freq_ngram , companies_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_freq_ngram = createNgramDF()[0]\n",
    "industry_freq_ngram = createNgramDF()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----+\n",
      "|       city|frequency|ngram|\n",
      "+-----------+---------+-----+\n",
      "|     Union,|        1|   []|\n",
      "|  Lynbrook,|        1|   []|\n",
      "| Fairfield,|        1|   []|\n",
      "|  Berkeley,|        1|   []|\n",
      "| Allendale,|        1|   []|\n",
      "|Parsippany,|        1|   []|\n",
      "|  Martinez,|        1|   []|\n",
      "| Manhasset,|        1|   []|\n",
      "|Burlingame,|        1|   []|\n",
      "|   Hayward,|        2|   []|\n",
      "|   Belmont,|        2|   []|\n",
      "| Manhattan,|        2|   []|\n",
      "|  Richmond,|        2|   []|\n",
      "|Emeryville,|        2|   []|\n",
      "|  Brooklyn,|        3|   []|\n",
      "|   Alameda,|        4|   []|\n",
      "|   Boulder,|        8|   []|\n",
      "|   Oakland,|        9|   []|\n",
      "|   Redmond,|       17|   []|\n",
      "| Sunnyvale,|       20|   []|\n",
      "|    Austin,|       26|   []|\n",
      "|   Atlanta,|       30|   []|\n",
      "|   Chicago,|       42|   []|\n",
      "|Washington,|       46|   []|\n",
      "|   Seattle,|       65|   []|\n",
      "|    Boston,|       72|   []|\n",
      "| Cambridge,|       75|   []|\n",
      "+-----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_freq_ngram.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|            industry|frequency|               ngram|\n",
      "+--------------------+---------+--------------------+\n",
      "| they provide inv...|       10|[ they, they prov...|\n",
      "|   Computer Hardware|        1| [computer hardware]|\n",
      "| sale or distribu...|       94|[ sale, sale or, ...|\n",
      "|           Insurance|        1|                  []|\n",
      "|   Health Care Plans|        1|[health care, car...|\n",
      "| http://www.ise.com/|        6|                  []|\n",
      "| services and pro...|       94|[ services, servi...|\n",
      "| depositary prefe...|       31|[ depositary, dep...|\n",
      "| exchange-traded ...|       31|[ exchange-traded...|\n",
      "|Consumer Packaged...|        1|[consumer package...|\n",
      "| services or tech...|        2|[ services, servi...|\n",
      "| plus any borrowi...|        1|[ plus, plus any,...|\n",
      "|     Credit Services|        3|   [credit services]|\n",
      "|        construction|        3|     [ construction]|\n",
      "| \"\"2020 Bonds\"\")....|        1|[ \"\"2020, \"\"2020 ...|\n",
      "|     Medical Devices|        3|   [medical devices]|\n",
      "|       Biotechnology|       53|                  []|\n",
      "|Retail - Apparel ...|        2|[retail -, - appa...|\n",
      "|http://www.invesc...|      157|                  []|\n",
      "|            military|        2|         [ military]|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "industry_freq_ngram.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
